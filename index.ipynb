{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_excel('test1.xlsx')\n",
    "question_list=[]\n",
    "is_hots_list=[]\n",
    "q_name='question'\n",
    "h_name=\"is_hots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_length = 20\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "num_epochs=150\n",
    "train_size=180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list.extend(df[q_name].tolist())\n",
    "is_hots_list.extend(df[h_name].tolist())\n",
    "\n",
    "training_data=question_list[:train_size]\n",
    "training_data_hots =is_hots_list[:train_size]\n",
    "testing_data=question_list[train_size:]\n",
    "testing_data_hots=is_hots_list[train_size:]\n",
    "\n",
    "tokenizer=Tokenizer(num_words=20, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(training_data)\n",
    "word_index=tokenizer.word_index\n",
    "\n",
    "padded = np.array(pad_sequences(tokenizer.texts_to_sequences(training_data), padding=padding_type, truncating=trunc_type, maxlen=max_length))\n",
    "sequence = np.array(pad_sequences(tokenizer.texts_to_sequences(training_data), padding=padding_type, truncating=trunc_type, maxlen=max_length))  # Use padded here\n",
    "\n",
    "# Same for testing data\n",
    "testpadded = np.array(pad_sequences(tokenizer.texts_to_sequences(testing_data), padding=padding_type, truncating=trunc_type, maxlen=max_length))\n",
    "testsequence = testpadded  \n",
    "\n",
    "is_hots_train = np.array(training_data_hots) # Convert list to NumPy array (correct labels)\n",
    "is_hots_test = np.array(testing_data_hots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: (None, 1)\n",
      "Labels shape: (152, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"Model output shape:\", model.layers[-1].output_shape)  # Should be (None, 1)\n",
    "print(\"Labels shape:\", sequence.shape)  # Should be (None, 1) for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step\n",
      "Predictions shape: (152, 1)\n",
      "Labels shape: (152, 20)\n",
      "Loss function: binary_crossentropy\n",
      "Model output shape: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "# #troubleshoothing\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. Verify Output Shape\n",
    "preds = model.predict(padded)\n",
    "print(\"Predictions shape:\", preds.shape)  # Should be (None, 1)\n",
    "\n",
    "# 2. Check Label Shape\n",
    "print(\"Labels shape:\", sequence.shape)   # Should be (None, 20)\n",
    "\n",
    "# 3. Examine Loss Function\n",
    "print(\"Loss function:\", model.loss)\n",
    "\n",
    "# 4. Debug with Print Statements (example)\n",
    "print(\"Model output shape:\", model.layers[-1].output_shape)\n",
    "# print(\"True label shape in loss calculation:\", tf.shape(sequence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5/5 - 2s - loss: 0.6914 - accuracy: 0.6382 - val_loss: 0.6850 - val_accuracy: 0.7843 - 2s/epoch - 340ms/step\n",
      "Epoch 2/150\n",
      "5/5 - 0s - loss: 0.6872 - accuracy: 0.6711 - val_loss: 0.6784 - val_accuracy: 0.7843 - 82ms/epoch - 16ms/step\n",
      "Epoch 3/150\n",
      "5/5 - 0s - loss: 0.6839 - accuracy: 0.6711 - val_loss: 0.6714 - val_accuracy: 0.7843 - 41ms/epoch - 8ms/step\n",
      "Epoch 4/150\n",
      "5/5 - 0s - loss: 0.6801 - accuracy: 0.6711 - val_loss: 0.6646 - val_accuracy: 0.7843 - 38ms/epoch - 8ms/step\n",
      "Epoch 5/150\n",
      "5/5 - 0s - loss: 0.6763 - accuracy: 0.6711 - val_loss: 0.6578 - val_accuracy: 0.7843 - 41ms/epoch - 8ms/step\n",
      "Epoch 6/150\n",
      "5/5 - 0s - loss: 0.6720 - accuracy: 0.6711 - val_loss: 0.6509 - val_accuracy: 0.7843 - 39ms/epoch - 8ms/step\n",
      "Epoch 7/150\n",
      "5/5 - 0s - loss: 0.6686 - accuracy: 0.6711 - val_loss: 0.6433 - val_accuracy: 0.7843 - 40ms/epoch - 8ms/step\n",
      "Epoch 8/150\n",
      "5/5 - 0s - loss: 0.6645 - accuracy: 0.6711 - val_loss: 0.6353 - val_accuracy: 0.7843 - 40ms/epoch - 8ms/step\n",
      "Epoch 9/150\n",
      "5/5 - 0s - loss: 0.6603 - accuracy: 0.6711 - val_loss: 0.6267 - val_accuracy: 0.7843 - 43ms/epoch - 9ms/step\n",
      "Epoch 10/150\n",
      "5/5 - 0s - loss: 0.6557 - accuracy: 0.6711 - val_loss: 0.6176 - val_accuracy: 0.7843 - 39ms/epoch - 8ms/step\n",
      "Epoch 11/150\n",
      "5/5 - 0s - loss: 0.6517 - accuracy: 0.6711 - val_loss: 0.6074 - val_accuracy: 0.7843 - 37ms/epoch - 7ms/step\n",
      "Epoch 12/150\n",
      "5/5 - 0s - loss: 0.6467 - accuracy: 0.6711 - val_loss: 0.5963 - val_accuracy: 0.7843 - 38ms/epoch - 8ms/step\n",
      "Epoch 13/150\n",
      "5/5 - 0s - loss: 0.6411 - accuracy: 0.6711 - val_loss: 0.5850 - val_accuracy: 0.7843 - 37ms/epoch - 7ms/step\n",
      "Epoch 14/150\n",
      "5/5 - 0s - loss: 0.6367 - accuracy: 0.6711 - val_loss: 0.5726 - val_accuracy: 0.7843 - 37ms/epoch - 7ms/step\n",
      "Epoch 15/150\n",
      "5/5 - 0s - loss: 0.6315 - accuracy: 0.6711 - val_loss: 0.5606 - val_accuracy: 0.7843 - 46ms/epoch - 9ms/step\n",
      "Epoch 16/150\n",
      "5/5 - 0s - loss: 0.6270 - accuracy: 0.6711 - val_loss: 0.5484 - val_accuracy: 0.7843 - 45ms/epoch - 9ms/step\n",
      "Epoch 17/150\n",
      "5/5 - 0s - loss: 0.6226 - accuracy: 0.6711 - val_loss: 0.5364 - val_accuracy: 0.7843 - 65ms/epoch - 13ms/step\n",
      "Epoch 18/150\n",
      "5/5 - 0s - loss: 0.6187 - accuracy: 0.6711 - val_loss: 0.5244 - val_accuracy: 0.7843 - 67ms/epoch - 13ms/step\n",
      "Epoch 19/150\n",
      "5/5 - 0s - loss: 0.6143 - accuracy: 0.6711 - val_loss: 0.5136 - val_accuracy: 0.7843 - 50ms/epoch - 10ms/step\n",
      "Epoch 20/150\n",
      "5/5 - 0s - loss: 0.6107 - accuracy: 0.6711 - val_loss: 0.5029 - val_accuracy: 0.7843 - 44ms/epoch - 9ms/step\n",
      "Epoch 21/150\n",
      "5/5 - 0s - loss: 0.6072 - accuracy: 0.6711 - val_loss: 0.4932 - val_accuracy: 0.7843 - 60ms/epoch - 12ms/step\n",
      "Epoch 22/150\n",
      "5/5 - 0s - loss: 0.6046 - accuracy: 0.6711 - val_loss: 0.4825 - val_accuracy: 0.7843 - 46ms/epoch - 9ms/step\n",
      "Epoch 23/150\n",
      "5/5 - 0s - loss: 0.6016 - accuracy: 0.6711 - val_loss: 0.4729 - val_accuracy: 0.7843 - 38ms/epoch - 8ms/step\n",
      "Epoch 24/150\n",
      "5/5 - 0s - loss: 0.5995 - accuracy: 0.6711 - val_loss: 0.4637 - val_accuracy: 0.7843 - 44ms/epoch - 9ms/step\n",
      "Epoch 25/150\n",
      "5/5 - 0s - loss: 0.5969 - accuracy: 0.6711 - val_loss: 0.4562 - val_accuracy: 0.7843 - 42ms/epoch - 8ms/step\n",
      "Epoch 26/150\n",
      "5/5 - 0s - loss: 0.5945 - accuracy: 0.6711 - val_loss: 0.4512 - val_accuracy: 0.8235 - 60ms/epoch - 12ms/step\n",
      "Epoch 27/150\n",
      "5/5 - 0s - loss: 0.5925 - accuracy: 0.6711 - val_loss: 0.4452 - val_accuracy: 0.8627 - 70ms/epoch - 14ms/step\n",
      "Epoch 28/150\n",
      "5/5 - 0s - loss: 0.5904 - accuracy: 0.6842 - val_loss: 0.4418 - val_accuracy: 0.8627 - 58ms/epoch - 12ms/step\n",
      "Epoch 29/150\n",
      "5/5 - 0s - loss: 0.5887 - accuracy: 0.6776 - val_loss: 0.4376 - val_accuracy: 0.9020 - 37ms/epoch - 7ms/step\n",
      "Epoch 30/150\n",
      "5/5 - 0s - loss: 0.5877 - accuracy: 0.6711 - val_loss: 0.4330 - val_accuracy: 0.9216 - 46ms/epoch - 9ms/step\n",
      "Epoch 31/150\n",
      "5/5 - 0s - loss: 0.5855 - accuracy: 0.6842 - val_loss: 0.4322 - val_accuracy: 0.9216 - 44ms/epoch - 9ms/step\n",
      "Epoch 32/150\n",
      "5/5 - 0s - loss: 0.5842 - accuracy: 0.6842 - val_loss: 0.4295 - val_accuracy: 0.9020 - 43ms/epoch - 9ms/step\n",
      "Epoch 33/150\n",
      "5/5 - 0s - loss: 0.5828 - accuracy: 0.6645 - val_loss: 0.4282 - val_accuracy: 0.8824 - 45ms/epoch - 9ms/step\n",
      "Epoch 34/150\n",
      "5/5 - 0s - loss: 0.5816 - accuracy: 0.6842 - val_loss: 0.4277 - val_accuracy: 0.8824 - 48ms/epoch - 10ms/step\n",
      "Epoch 35/150\n",
      "5/5 - 0s - loss: 0.5802 - accuracy: 0.6908 - val_loss: 0.4250 - val_accuracy: 0.8824 - 56ms/epoch - 11ms/step\n",
      "Epoch 36/150\n",
      "5/5 - 0s - loss: 0.5793 - accuracy: 0.6842 - val_loss: 0.4235 - val_accuracy: 0.8627 - 55ms/epoch - 11ms/step\n",
      "Epoch 37/150\n",
      "5/5 - 0s - loss: 0.5787 - accuracy: 0.6776 - val_loss: 0.4183 - val_accuracy: 0.8627 - 48ms/epoch - 10ms/step\n",
      "Epoch 38/150\n",
      "5/5 - 0s - loss: 0.5773 - accuracy: 0.6842 - val_loss: 0.4168 - val_accuracy: 0.8627 - 49ms/epoch - 10ms/step\n",
      "Epoch 39/150\n",
      "5/5 - 0s - loss: 0.5765 - accuracy: 0.6908 - val_loss: 0.4146 - val_accuracy: 0.8627 - 42ms/epoch - 8ms/step\n",
      "Epoch 40/150\n",
      "5/5 - 0s - loss: 0.5755 - accuracy: 0.6908 - val_loss: 0.4146 - val_accuracy: 0.8431 - 46ms/epoch - 9ms/step\n",
      "Epoch 41/150\n",
      "5/5 - 0s - loss: 0.5747 - accuracy: 0.6974 - val_loss: 0.4134 - val_accuracy: 0.8431 - 50ms/epoch - 10ms/step\n",
      "Epoch 42/150\n",
      "5/5 - 0s - loss: 0.5743 - accuracy: 0.6908 - val_loss: 0.4148 - val_accuracy: 0.8431 - 52ms/epoch - 10ms/step\n",
      "Epoch 43/150\n",
      "5/5 - 0s - loss: 0.5732 - accuracy: 0.6776 - val_loss: 0.4111 - val_accuracy: 0.8431 - 60ms/epoch - 12ms/step\n",
      "Epoch 44/150\n",
      "5/5 - 0s - loss: 0.5721 - accuracy: 0.6711 - val_loss: 0.4101 - val_accuracy: 0.8431 - 52ms/epoch - 10ms/step\n",
      "Epoch 45/150\n",
      "5/5 - 0s - loss: 0.5715 - accuracy: 0.6776 - val_loss: 0.4098 - val_accuracy: 0.8431 - 49ms/epoch - 10ms/step\n",
      "Epoch 46/150\n",
      "5/5 - 0s - loss: 0.5712 - accuracy: 0.6776 - val_loss: 0.4082 - val_accuracy: 0.8431 - 46ms/epoch - 9ms/step\n",
      "Epoch 47/150\n",
      "5/5 - 0s - loss: 0.5704 - accuracy: 0.6776 - val_loss: 0.4082 - val_accuracy: 0.8431 - 39ms/epoch - 8ms/step\n",
      "Epoch 48/150\n",
      "5/5 - 0s - loss: 0.5699 - accuracy: 0.6776 - val_loss: 0.4099 - val_accuracy: 0.8431 - 43ms/epoch - 9ms/step\n",
      "Epoch 49/150\n",
      "5/5 - 0s - loss: 0.5692 - accuracy: 0.6908 - val_loss: 0.4089 - val_accuracy: 0.8627 - 42ms/epoch - 8ms/step\n",
      "Epoch 50/150\n",
      "5/5 - 0s - loss: 0.5687 - accuracy: 0.6842 - val_loss: 0.4055 - val_accuracy: 0.8431 - 51ms/epoch - 10ms/step\n",
      "Epoch 51/150\n",
      "5/5 - 0s - loss: 0.5680 - accuracy: 0.6908 - val_loss: 0.4029 - val_accuracy: 0.8431 - 57ms/epoch - 11ms/step\n",
      "Epoch 52/150\n",
      "5/5 - 0s - loss: 0.5674 - accuracy: 0.6908 - val_loss: 0.4029 - val_accuracy: 0.8627 - 51ms/epoch - 10ms/step\n",
      "Epoch 53/150\n",
      "5/5 - 0s - loss: 0.5671 - accuracy: 0.6908 - val_loss: 0.4008 - val_accuracy: 0.8627 - 49ms/epoch - 10ms/step\n",
      "Epoch 54/150\n",
      "5/5 - 0s - loss: 0.5665 - accuracy: 0.6842 - val_loss: 0.4030 - val_accuracy: 0.8431 - 51ms/epoch - 10ms/step\n",
      "Epoch 55/150\n",
      "5/5 - 0s - loss: 0.5657 - accuracy: 0.6842 - val_loss: 0.4012 - val_accuracy: 0.8431 - 44ms/epoch - 9ms/step\n",
      "Epoch 56/150\n",
      "5/5 - 0s - loss: 0.5651 - accuracy: 0.6842 - val_loss: 0.4015 - val_accuracy: 0.8431 - 44ms/epoch - 9ms/step\n",
      "Epoch 57/150\n",
      "5/5 - 0s - loss: 0.5645 - accuracy: 0.6908 - val_loss: 0.4021 - val_accuracy: 0.8431 - 40ms/epoch - 8ms/step\n",
      "Epoch 58/150\n",
      "5/5 - 0s - loss: 0.5641 - accuracy: 0.6908 - val_loss: 0.4034 - val_accuracy: 0.8431 - 43ms/epoch - 9ms/step\n",
      "Epoch 59/150\n",
      "5/5 - 0s - loss: 0.5636 - accuracy: 0.6974 - val_loss: 0.4019 - val_accuracy: 0.8431 - 42ms/epoch - 8ms/step\n",
      "Epoch 60/150\n",
      "5/5 - 0s - loss: 0.5632 - accuracy: 0.6974 - val_loss: 0.3994 - val_accuracy: 0.8431 - 44ms/epoch - 9ms/step\n",
      "Epoch 61/150\n",
      "5/5 - 0s - loss: 0.5623 - accuracy: 0.6974 - val_loss: 0.3996 - val_accuracy: 0.8431 - 41ms/epoch - 8ms/step\n",
      "Epoch 62/150\n",
      "5/5 - 0s - loss: 0.5618 - accuracy: 0.6908 - val_loss: 0.4015 - val_accuracy: 0.8431 - 45ms/epoch - 9ms/step\n",
      "Epoch 63/150\n",
      "5/5 - 0s - loss: 0.5613 - accuracy: 0.6908 - val_loss: 0.4020 - val_accuracy: 0.8431 - 43ms/epoch - 9ms/step\n",
      "Epoch 64/150\n",
      "5/5 - 0s - loss: 0.5612 - accuracy: 0.6908 - val_loss: 0.3984 - val_accuracy: 0.8431 - 41ms/epoch - 8ms/step\n",
      "Epoch 65/150\n",
      "5/5 - 0s - loss: 0.5602 - accuracy: 0.6908 - val_loss: 0.3998 - val_accuracy: 0.8431 - 51ms/epoch - 10ms/step\n",
      "Epoch 66/150\n",
      "5/5 - 0s - loss: 0.5596 - accuracy: 0.6908 - val_loss: 0.3994 - val_accuracy: 0.8431 - 58ms/epoch - 12ms/step\n",
      "Epoch 67/150\n",
      "5/5 - 0s - loss: 0.5590 - accuracy: 0.6908 - val_loss: 0.3983 - val_accuracy: 0.8431 - 51ms/epoch - 10ms/step\n",
      "Epoch 68/150\n",
      "5/5 - 0s - loss: 0.5587 - accuracy: 0.6974 - val_loss: 0.3987 - val_accuracy: 0.8431 - 45ms/epoch - 9ms/step\n",
      "Epoch 69/150\n",
      "5/5 - 0s - loss: 0.5578 - accuracy: 0.6974 - val_loss: 0.3971 - val_accuracy: 0.8431 - 40ms/epoch - 8ms/step\n",
      "Epoch 70/150\n",
      "5/5 - 0s - loss: 0.5574 - accuracy: 0.6974 - val_loss: 0.3954 - val_accuracy: 0.8431 - 43ms/epoch - 9ms/step\n",
      "Epoch 71/150\n",
      "5/5 - 0s - loss: 0.5577 - accuracy: 0.6974 - val_loss: 0.3979 - val_accuracy: 0.8431 - 44ms/epoch - 9ms/step\n",
      "Epoch 72/150\n",
      "5/5 - 0s - loss: 0.5562 - accuracy: 0.6974 - val_loss: 0.3961 - val_accuracy: 0.8431 - 45ms/epoch - 9ms/step\n",
      "Epoch 73/150\n",
      "5/5 - 0s - loss: 0.5558 - accuracy: 0.6974 - val_loss: 0.3963 - val_accuracy: 0.8431 - 43ms/epoch - 9ms/step\n",
      "Epoch 74/150\n",
      "5/5 - 0s - loss: 0.5553 - accuracy: 0.6974 - val_loss: 0.3938 - val_accuracy: 0.8431 - 51ms/epoch - 10ms/step\n",
      "Epoch 75/150\n",
      "5/5 - 0s - loss: 0.5548 - accuracy: 0.6974 - val_loss: 0.3942 - val_accuracy: 0.8431 - 45ms/epoch - 9ms/step\n",
      "Epoch 76/150\n",
      "5/5 - 0s - loss: 0.5542 - accuracy: 0.6974 - val_loss: 0.3932 - val_accuracy: 0.8431 - 44ms/epoch - 9ms/step\n",
      "Epoch 77/150\n",
      "5/5 - 0s - loss: 0.5535 - accuracy: 0.6974 - val_loss: 0.3941 - val_accuracy: 0.8431 - 42ms/epoch - 8ms/step\n",
      "Epoch 78/150\n",
      "5/5 - 0s - loss: 0.5530 - accuracy: 0.6974 - val_loss: 0.3964 - val_accuracy: 0.8627 - 45ms/epoch - 9ms/step\n",
      "Epoch 79/150\n",
      "5/5 - 0s - loss: 0.5525 - accuracy: 0.6974 - val_loss: 0.3971 - val_accuracy: 0.8627 - 43ms/epoch - 9ms/step\n",
      "Epoch 80/150\n",
      "5/5 - 0s - loss: 0.5519 - accuracy: 0.6974 - val_loss: 0.3959 - val_accuracy: 0.8431 - 44ms/epoch - 9ms/step\n",
      "Epoch 81/150\n",
      "5/5 - 0s - loss: 0.5513 - accuracy: 0.6974 - val_loss: 0.3960 - val_accuracy: 0.8627 - 46ms/epoch - 9ms/step\n",
      "Epoch 82/150\n",
      "5/5 - 0s - loss: 0.5507 - accuracy: 0.6974 - val_loss: 0.3938 - val_accuracy: 0.8431 - 46ms/epoch - 9ms/step\n",
      "Epoch 83/150\n",
      "5/5 - 0s - loss: 0.5503 - accuracy: 0.6974 - val_loss: 0.3943 - val_accuracy: 0.8431 - 42ms/epoch - 8ms/step\n",
      "Epoch 84/150\n",
      "5/5 - 0s - loss: 0.5496 - accuracy: 0.7039 - val_loss: 0.3932 - val_accuracy: 0.8431 - 43ms/epoch - 9ms/step\n",
      "Epoch 85/150\n",
      "5/5 - 0s - loss: 0.5490 - accuracy: 0.6974 - val_loss: 0.3935 - val_accuracy: 0.8627 - 42ms/epoch - 8ms/step\n",
      "Epoch 86/150\n",
      "5/5 - 0s - loss: 0.5484 - accuracy: 0.6974 - val_loss: 0.3940 - val_accuracy: 0.8627 - 81ms/epoch - 16ms/step\n",
      "Epoch 87/150\n",
      "5/5 - 0s - loss: 0.5480 - accuracy: 0.7039 - val_loss: 0.3945 - val_accuracy: 0.8627 - 45ms/epoch - 9ms/step\n",
      "Epoch 88/150\n",
      "5/5 - 0s - loss: 0.5474 - accuracy: 0.7105 - val_loss: 0.3923 - val_accuracy: 0.8627 - 43ms/epoch - 9ms/step\n",
      "Epoch 89/150\n",
      "5/5 - 0s - loss: 0.5468 - accuracy: 0.7105 - val_loss: 0.3920 - val_accuracy: 0.8431 - 41ms/epoch - 8ms/step\n",
      "Epoch 90/150\n",
      "5/5 - 0s - loss: 0.5463 - accuracy: 0.7105 - val_loss: 0.3934 - val_accuracy: 0.8627 - 40ms/epoch - 8ms/step\n",
      "Epoch 91/150\n",
      "5/5 - 0s - loss: 0.5456 - accuracy: 0.7105 - val_loss: 0.3939 - val_accuracy: 0.8627 - 40ms/epoch - 8ms/step\n",
      "Epoch 92/150\n",
      "5/5 - 0s - loss: 0.5452 - accuracy: 0.7105 - val_loss: 0.3933 - val_accuracy: 0.8431 - 42ms/epoch - 8ms/step\n",
      "Epoch 93/150\n",
      "5/5 - 0s - loss: 0.5445 - accuracy: 0.7105 - val_loss: 0.3925 - val_accuracy: 0.8431 - 42ms/epoch - 8ms/step\n",
      "Epoch 94/150\n",
      "5/5 - 0s - loss: 0.5444 - accuracy: 0.7171 - val_loss: 0.3935 - val_accuracy: 0.8431 - 42ms/epoch - 8ms/step\n",
      "Epoch 95/150\n",
      "5/5 - 0s - loss: 0.5437 - accuracy: 0.7171 - val_loss: 0.3910 - val_accuracy: 0.8431 - 45ms/epoch - 9ms/step\n",
      "Epoch 96/150\n",
      "5/5 - 0s - loss: 0.5431 - accuracy: 0.7171 - val_loss: 0.3896 - val_accuracy: 0.8431 - 42ms/epoch - 8ms/step\n",
      "Epoch 97/150\n",
      "5/5 - 0s - loss: 0.5425 - accuracy: 0.7171 - val_loss: 0.3923 - val_accuracy: 0.8431 - 43ms/epoch - 9ms/step\n",
      "Epoch 98/150\n",
      "5/5 - 0s - loss: 0.5421 - accuracy: 0.7171 - val_loss: 0.3934 - val_accuracy: 0.8431 - 41ms/epoch - 8ms/step\n",
      "Epoch 99/150\n",
      "5/5 - 0s - loss: 0.5414 - accuracy: 0.7171 - val_loss: 0.3933 - val_accuracy: 0.8431 - 43ms/epoch - 9ms/step\n",
      "Epoch 100/150\n",
      "5/5 - 0s - loss: 0.5408 - accuracy: 0.7171 - val_loss: 0.3916 - val_accuracy: 0.8431 - 42ms/epoch - 8ms/step\n",
      "Epoch 101/150\n",
      "5/5 - 0s - loss: 0.5402 - accuracy: 0.7171 - val_loss: 0.3891 - val_accuracy: 0.8431 - 42ms/epoch - 8ms/step\n",
      "Epoch 102/150\n",
      "5/5 - 0s - loss: 0.5396 - accuracy: 0.7171 - val_loss: 0.3878 - val_accuracy: 0.8431 - 41ms/epoch - 8ms/step\n",
      "Epoch 103/150\n",
      "5/5 - 0s - loss: 0.5391 - accuracy: 0.7171 - val_loss: 0.3887 - val_accuracy: 0.8431 - 45ms/epoch - 9ms/step\n",
      "Epoch 104/150\n",
      "5/5 - 0s - loss: 0.5386 - accuracy: 0.7237 - val_loss: 0.3904 - val_accuracy: 0.8431 - 43ms/epoch - 9ms/step\n",
      "Epoch 105/150\n",
      "5/5 - 0s - loss: 0.5381 - accuracy: 0.7237 - val_loss: 0.3915 - val_accuracy: 0.8431 - 44ms/epoch - 9ms/step\n",
      "Epoch 106/150\n",
      "5/5 - 0s - loss: 0.5375 - accuracy: 0.7237 - val_loss: 0.3905 - val_accuracy: 0.8431 - 43ms/epoch - 9ms/step\n",
      "Epoch 107/150\n",
      "5/5 - 0s - loss: 0.5368 - accuracy: 0.7237 - val_loss: 0.3902 - val_accuracy: 0.8431 - 43ms/epoch - 9ms/step\n",
      "Epoch 108/150\n",
      "5/5 - 0s - loss: 0.5364 - accuracy: 0.7237 - val_loss: 0.3915 - val_accuracy: 0.8235 - 46ms/epoch - 9ms/step\n",
      "Epoch 109/150\n",
      "5/5 - 0s - loss: 0.5358 - accuracy: 0.7237 - val_loss: 0.3919 - val_accuracy: 0.8235 - 41ms/epoch - 8ms/step\n",
      "Epoch 110/150\n",
      "5/5 - 0s - loss: 0.5357 - accuracy: 0.7237 - val_loss: 0.3946 - val_accuracy: 0.8235 - 44ms/epoch - 9ms/step\n",
      "Epoch 111/150\n",
      "5/5 - 0s - loss: 0.5353 - accuracy: 0.7237 - val_loss: 0.3912 - val_accuracy: 0.8235 - 44ms/epoch - 9ms/step\n",
      "Epoch 112/150\n",
      "5/5 - 0s - loss: 0.5346 - accuracy: 0.7237 - val_loss: 0.3929 - val_accuracy: 0.8235 - 43ms/epoch - 9ms/step\n",
      "Epoch 113/150\n",
      "5/5 - 0s - loss: 0.5337 - accuracy: 0.7303 - val_loss: 0.3931 - val_accuracy: 0.8235 - 44ms/epoch - 9ms/step\n",
      "Epoch 114/150\n",
      "5/5 - 0s - loss: 0.5331 - accuracy: 0.7303 - val_loss: 0.3907 - val_accuracy: 0.8235 - 44ms/epoch - 9ms/step\n",
      "Epoch 115/150\n",
      "5/5 - 0s - loss: 0.5328 - accuracy: 0.7237 - val_loss: 0.3889 - val_accuracy: 0.8235 - 41ms/epoch - 8ms/step\n",
      "Epoch 116/150\n",
      "5/5 - 0s - loss: 0.5319 - accuracy: 0.7303 - val_loss: 0.3905 - val_accuracy: 0.8235 - 45ms/epoch - 9ms/step\n",
      "Epoch 117/150\n",
      "5/5 - 0s - loss: 0.5321 - accuracy: 0.7303 - val_loss: 0.3905 - val_accuracy: 0.8235 - 42ms/epoch - 8ms/step\n",
      "Epoch 118/150\n",
      "5/5 - 0s - loss: 0.5316 - accuracy: 0.7303 - val_loss: 0.3889 - val_accuracy: 0.8235 - 43ms/epoch - 9ms/step\n",
      "Epoch 119/150\n",
      "5/5 - 0s - loss: 0.5306 - accuracy: 0.7303 - val_loss: 0.3886 - val_accuracy: 0.8235 - 43ms/epoch - 9ms/step\n",
      "Epoch 120/150\n",
      "5/5 - 0s - loss: 0.5303 - accuracy: 0.7303 - val_loss: 0.3909 - val_accuracy: 0.8235 - 41ms/epoch - 8ms/step\n",
      "Epoch 121/150\n",
      "5/5 - 0s - loss: 0.5298 - accuracy: 0.7303 - val_loss: 0.3926 - val_accuracy: 0.8235 - 44ms/epoch - 9ms/step\n",
      "Epoch 122/150\n",
      "5/5 - 0s - loss: 0.5291 - accuracy: 0.7303 - val_loss: 0.3907 - val_accuracy: 0.8235 - 41ms/epoch - 8ms/step\n",
      "Epoch 123/150\n",
      "5/5 - 0s - loss: 0.5290 - accuracy: 0.7303 - val_loss: 0.3915 - val_accuracy: 0.8235 - 41ms/epoch - 8ms/step\n",
      "Epoch 124/150\n",
      "5/5 - 0s - loss: 0.5284 - accuracy: 0.7303 - val_loss: 0.3897 - val_accuracy: 0.8235 - 43ms/epoch - 9ms/step\n",
      "Epoch 125/150\n",
      "5/5 - 0s - loss: 0.5277 - accuracy: 0.7303 - val_loss: 0.3919 - val_accuracy: 0.8235 - 47ms/epoch - 9ms/step\n",
      "Epoch 126/150\n",
      "5/5 - 0s - loss: 0.5272 - accuracy: 0.7303 - val_loss: 0.3922 - val_accuracy: 0.8235 - 42ms/epoch - 8ms/step\n",
      "Epoch 127/150\n",
      "5/5 - 0s - loss: 0.5268 - accuracy: 0.7303 - val_loss: 0.3932 - val_accuracy: 0.8235 - 40ms/epoch - 8ms/step\n",
      "Epoch 128/150\n",
      "5/5 - 0s - loss: 0.5263 - accuracy: 0.7303 - val_loss: 0.3913 - val_accuracy: 0.8235 - 43ms/epoch - 9ms/step\n",
      "Epoch 129/150\n",
      "5/5 - 0s - loss: 0.5259 - accuracy: 0.7303 - val_loss: 0.3901 - val_accuracy: 0.8235 - 45ms/epoch - 9ms/step\n",
      "Epoch 130/150\n",
      "5/5 - 0s - loss: 0.5254 - accuracy: 0.7303 - val_loss: 0.3911 - val_accuracy: 0.8235 - 45ms/epoch - 9ms/step\n",
      "Epoch 131/150\n",
      "5/5 - 0s - loss: 0.5250 - accuracy: 0.7303 - val_loss: 0.3915 - val_accuracy: 0.8235 - 44ms/epoch - 9ms/step\n",
      "Epoch 132/150\n",
      "5/5 - 0s - loss: 0.5246 - accuracy: 0.7303 - val_loss: 0.3915 - val_accuracy: 0.8235 - 44ms/epoch - 9ms/step\n",
      "Epoch 133/150\n",
      "5/5 - 0s - loss: 0.5242 - accuracy: 0.7303 - val_loss: 0.3925 - val_accuracy: 0.8235 - 41ms/epoch - 8ms/step\n",
      "Epoch 134/150\n",
      "5/5 - 0s - loss: 0.5237 - accuracy: 0.7303 - val_loss: 0.3917 - val_accuracy: 0.8235 - 45ms/epoch - 9ms/step\n",
      "Epoch 135/150\n",
      "5/5 - 0s - loss: 0.5235 - accuracy: 0.7368 - val_loss: 0.3932 - val_accuracy: 0.8431 - 44ms/epoch - 9ms/step\n",
      "Epoch 136/150\n",
      "5/5 - 0s - loss: 0.5229 - accuracy: 0.7368 - val_loss: 0.3926 - val_accuracy: 0.8431 - 42ms/epoch - 8ms/step\n",
      "Epoch 137/150\n",
      "5/5 - 0s - loss: 0.5226 - accuracy: 0.7434 - val_loss: 0.3914 - val_accuracy: 0.8431 - 43ms/epoch - 9ms/step\n",
      "Epoch 138/150\n",
      "5/5 - 0s - loss: 0.5233 - accuracy: 0.7434 - val_loss: 0.3855 - val_accuracy: 0.8627 - 43ms/epoch - 9ms/step\n",
      "Epoch 139/150\n",
      "5/5 - 0s - loss: 0.5220 - accuracy: 0.7500 - val_loss: 0.3869 - val_accuracy: 0.8627 - 45ms/epoch - 9ms/step\n",
      "Epoch 140/150\n",
      "5/5 - 0s - loss: 0.5217 - accuracy: 0.7500 - val_loss: 0.3867 - val_accuracy: 0.8627 - 45ms/epoch - 9ms/step\n",
      "Epoch 141/150\n",
      "5/5 - 0s - loss: 0.5212 - accuracy: 0.7566 - val_loss: 0.3907 - val_accuracy: 0.8431 - 44ms/epoch - 9ms/step\n",
      "Epoch 142/150\n",
      "5/5 - 0s - loss: 0.5207 - accuracy: 0.7500 - val_loss: 0.3924 - val_accuracy: 0.8431 - 43ms/epoch - 9ms/step\n",
      "Epoch 143/150\n",
      "5/5 - 0s - loss: 0.5206 - accuracy: 0.7500 - val_loss: 0.3935 - val_accuracy: 0.8431 - 51ms/epoch - 10ms/step\n",
      "Epoch 144/150\n",
      "5/5 - 0s - loss: 0.5212 - accuracy: 0.7500 - val_loss: 0.3971 - val_accuracy: 0.8431 - 43ms/epoch - 9ms/step\n",
      "Epoch 145/150\n",
      "5/5 - 0s - loss: 0.5201 - accuracy: 0.7500 - val_loss: 0.3925 - val_accuracy: 0.8627 - 44ms/epoch - 9ms/step\n",
      "Epoch 146/150\n",
      "5/5 - 0s - loss: 0.5193 - accuracy: 0.7566 - val_loss: 0.3915 - val_accuracy: 0.8627 - 46ms/epoch - 9ms/step\n",
      "Epoch 147/150\n",
      "5/5 - 0s - loss: 0.5193 - accuracy: 0.7566 - val_loss: 0.3885 - val_accuracy: 0.8627 - 48ms/epoch - 10ms/step\n",
      "Epoch 148/150\n",
      "5/5 - 0s - loss: 0.5189 - accuracy: 0.7500 - val_loss: 0.3884 - val_accuracy: 0.8627 - 40ms/epoch - 8ms/step\n",
      "Epoch 149/150\n",
      "5/5 - 0s - loss: 0.5187 - accuracy: 0.7566 - val_loss: 0.3902 - val_accuracy: 0.8627 - 42ms/epoch - 8ms/step\n",
      "Epoch 150/150\n",
      "5/5 - 0s - loss: 0.5183 - accuracy: 0.7566 - val_loss: 0.3900 - val_accuracy: 0.8627 - 43ms/epoch - 9ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(padded, is_hots_train, epochs=num_epochs,\n",
    "                    validation_data=(testpadded, is_hots_test), verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
